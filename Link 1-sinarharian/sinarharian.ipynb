{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "import csv\n",
    "import time\n",
    "import re\n",
    "import requests \n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def english_months_converter(malay_month):\n",
    "    if \"Januari\" in malay_month:\n",
    "        malay_month = malay_month.replace('Januari', 'January')\n",
    "    elif 'Februari' in malay_month:\n",
    "        malay_month = malay_month.replace('Februari', 'February')\n",
    "    elif 'Mac' in malay_month:\n",
    "        malay_month = malay_month.replace('Mac', 'March')\n",
    "    elif 'Mei' in malay_month:\n",
    "        malay_month = malay_month.replace('Mei', 'May')\n",
    "    elif 'Jun' in malay_month:\n",
    "        malay_month = malay_month.replace('Jun', 'June')\n",
    "    elif 'Julai' in malay_month:\n",
    "        malay_month = malay_month.replace('Julai', 'July')\n",
    "    elif 'Ogos' in malay_month:\n",
    "        malay_month = malay_month.replace('Ogos', 'August')\n",
    "    elif 'Oktober' in malay_month:\n",
    "        malay_month = malay_month.replace('Oktober', 'October')\n",
    "    elif 'Disember' in malay_month:\n",
    "        malay_month = malay_month.replace('Disember', 'December')    \n",
    "    return malay_month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_pattern = r\"(\\d{1,2} [a-zA-Z]+ \\d{4})\"\n",
    "time_pattern = r\"(?P<hour>\\d{1,2}):(?P<minute>\\d{2})(?P<meridiem>am|pm)\"\n",
    "\n",
    "def extract_properties(links, writer):\n",
    "    # need to get the first 6 articles, as the other 4 are the 'popular section'\n",
    "    for link in links:\n",
    "      \n",
    "      # Within div tag, find article-title tag, get its title text\n",
    "\n",
    "      # Ex: Anwar dedah perolehan vaksin tanpa persetujuan Peguam Negara\n",
    "      article_title = link.find('div', attrs='article-title').text\n",
    "\n",
    "      # Ex: 11 Januari 2021 07:38pm\n",
    "      time_date_properties = link.find('div', attrs='timespan').text\n",
    "\n",
    "      # converted: 12 January 2021 01:15pm\n",
    "      date_converted = english_months_converter(time_date_properties)\n",
    "\n",
    "      date_match = re.search(date_pattern, date_converted)\n",
    "      time_match = re.search(time_pattern, date_converted)\n",
    "\n",
    "      if date_match and time_match:\n",
    "            date_extract = date_match.group(1)\n",
    "            time_extract = time_match.group()\n",
    "\n",
    "      # Ex: 2021-01-12\n",
    "      dateobj = datetime.strptime(date_extract,'%d %B %Y').date()\n",
    "      \n",
    "     # 2:11 pm --> 14:11:00\n",
    "      timeobj = datetime.strptime(time_extract, '%I:%M%p').time()\n",
    "\n",
    "      # Extract value of href attribute from 'a' tag using dictionary-style access\n",
    "      web_address = link.find('div', attrs='article-desc').find('a')['href']\n",
    "\n",
    "\n",
    "      short_description = link.find('div', attrs='article-desc').text\n",
    "\n",
    "      # write each as a row in csv file\n",
    "      writer.writerow([article_title, dateobj, timeobj, web_address, short_description])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Page:  1\n",
      "Page 1 has 10 links\n",
      "CSV file saved successfully for Page: 1\n",
      "Processing Page:  2\n",
      "Page 2 has 10 links\n",
      "CSV file saved successfully for Page: 2\n",
      "Processing Page:  3\n",
      "Page 3 has 10 links\n",
      "CSV file saved successfully for Page: 3\n",
      "Processing Page:  4\n",
      "Page 4 has 10 links\n",
      "CSV file saved successfully for Page: 4\n",
      "Processing Page:  5\n",
      "Page 5 has 10 links\n",
      "CSV file saved successfully for Page: 5\n",
      "Processing Page:  6\n",
      "Page 6 has 10 links\n",
      "CSV file saved successfully for Page: 6\n",
      "Processing Page:  7\n",
      "Page 7 has 10 links\n",
      "CSV file saved successfully for Page: 7\n",
      "Processing Page:  8\n",
      "Page 8 has 10 links\n",
      "CSV file saved successfully for Page: 8\n",
      "Processing Page:  9\n",
      "Page 9 has 10 links\n",
      "CSV file saved successfully for Page: 9\n",
      "Processing Page:  10\n",
      "Page 10 has 10 links\n",
      "CSV file saved successfully for Page: 10\n",
      "Processing Page:  11\n",
      "Page 11 has 10 links\n",
      "CSV file saved successfully for Page: 11\n",
      "Processing Page:  12\n",
      "Page 12 has 10 links\n",
      "CSV file saved successfully for Page: 12\n",
      "Processing Page:  13\n",
      "Page 13 has 10 links\n",
      "CSV file saved successfully for Page: 13\n",
      "Processing Page:  14\n",
      "Page 14 has 10 links\n",
      "CSV file saved successfully for Page: 14\n",
      "Processing Page:  15\n",
      "Page 15 has 10 links\n",
      "CSV file saved successfully for Page: 15\n",
      "Processing Page:  16\n",
      "Page 16 has 10 links\n",
      "CSV file saved successfully for Page: 16\n",
      "Processing Page:  17\n",
      "Page 17 has 10 links\n",
      "CSV file saved successfully for Page: 17\n",
      "Processing Page:  18\n",
      "Page 18 has 10 links\n",
      "CSV file saved successfully for Page: 18\n",
      "Processing Page:  19\n",
      "Page 19 has 10 links\n",
      "CSV file saved successfully for Page: 19\n",
      "Processing Page:  20\n",
      "Page 20 has 10 links\n",
      "CSV file saved successfully for Page: 20\n",
      "Processing Page:  21\n",
      "Page 21 has 10 links\n",
      "CSV file saved successfully for Page: 21\n",
      "Processing Page:  22\n",
      "Page 22 has 10 links\n",
      "CSV file saved successfully for Page: 22\n",
      "Processing Page:  23\n",
      "Page 23 has 10 links\n",
      "CSV file saved successfully for Page: 23\n",
      "Processing Page:  24\n",
      "Page 24 has 10 links\n",
      "CSV file saved successfully for Page: 24\n",
      "Processing Page:  25\n",
      "Page 25 has 10 links\n",
      "CSV file saved successfully for Page: 25\n",
      "Processing Page:  26\n",
      "Page 26 has 0 links\n",
      "CSV file saved successfully for Page: 26\n",
      "Processing Page:  27\n",
      "Page 27 has 10 links\n",
      "CSV file saved successfully for Page: 27\n",
      "Processing Page:  28\n",
      "Page 28 has 10 links\n",
      "CSV file saved successfully for Page: 28\n",
      "Processing Page:  29\n",
      "Page 29 has 10 links\n",
      "CSV file saved successfully for Page: 29\n",
      "Processing Page:  30\n",
      "Page 30 has 10 links\n",
      "CSV file saved successfully for Page: 30\n",
      "Processing Page:  31\n",
      "Page 31 has 10 links\n",
      "CSV file saved successfully for Page: 31\n",
      "Processing Page:  32\n",
      "Page 32 has 10 links\n",
      "CSV file saved successfully for Page: 32\n",
      "Processing Page:  33\n",
      "Page 33 has 10 links\n",
      "CSV file saved successfully for Page: 33\n",
      "Processing Page:  34\n",
      "Page 34 has 10 links\n",
      "CSV file saved successfully for Page: 34\n",
      "Processing Page:  35\n",
      "Page 35 has 10 links\n",
      "CSV file saved successfully for Page: 35\n",
      "Processing Page:  36\n",
      "Page 36 has 10 links\n",
      "CSV file saved successfully for Page: 36\n",
      "Processing Page:  37\n",
      "Page 37 has 10 links\n",
      "CSV file saved successfully for Page: 37\n",
      "Processing Page:  38\n",
      "Page 38 has 10 links\n",
      "CSV file saved successfully for Page: 38\n",
      "Processing Page:  39\n",
      "Page 39 has 10 links\n",
      "CSV file saved successfully for Page: 39\n",
      "Processing Page:  40\n",
      "Page 40 has 10 links\n",
      "CSV file saved successfully for Page: 40\n",
      "Processing Page:  41\n",
      "Page 41 has 10 links\n",
      "CSV file saved successfully for Page: 41\n",
      "Processing Page:  42\n",
      "Page 42 has 10 links\n",
      "CSV file saved successfully for Page: 42\n",
      "Processing Page:  43\n",
      "Page 43 has 10 links\n",
      "CSV file saved successfully for Page: 43\n",
      "Processing Page:  44\n",
      "Page 44 has 10 links\n",
      "CSV file saved successfully for Page: 44\n",
      "Processing Page:  45\n",
      "Page 45 has 10 links\n",
      "CSV file saved successfully for Page: 45\n",
      "Processing Page:  46\n",
      "Page 46 has 10 links\n",
      "CSV file saved successfully for Page: 46\n",
      "Processing Page:  47\n",
      "Page 47 has 10 links\n",
      "CSV file saved successfully for Page: 47\n",
      "Processing Page:  48\n",
      "Page 48 has 10 links\n",
      "CSV file saved successfully for Page: 48\n",
      "Processing Page:  49\n",
      "Page 49 has 10 links\n",
      "CSV file saved successfully for Page: 49\n",
      "Processing Page:  50\n",
      "Page 50 has 10 links\n",
      "CSV file saved successfully for Page: 50\n",
      "Processing Page:  51\n",
      "Page 51 has 10 links\n",
      "CSV file saved successfully for Page: 51\n",
      "Processing Page:  52\n",
      "Page 52 has 10 links\n",
      "CSV file saved successfully for Page: 52\n",
      "Processing Page:  53\n",
      "Page 53 has 10 links\n",
      "CSV file saved successfully for Page: 53\n",
      "Processing Page:  54\n",
      "Page 54 has 10 links\n",
      "CSV file saved successfully for Page: 54\n",
      "Processing Page:  55\n",
      "Page 55 has 10 links\n",
      "CSV file saved successfully for Page: 55\n",
      "Processing Page:  56\n",
      "Page 56 has 10 links\n",
      "CSV file saved successfully for Page: 56\n",
      "Processing Page:  57\n",
      "Page 57 has 10 links\n",
      "CSV file saved successfully for Page: 57\n",
      "Processing Page:  58\n",
      "Page 58 has 10 links\n",
      "CSV file saved successfully for Page: 58\n",
      "Processing Page:  59\n",
      "Page 59 has 10 links\n",
      "CSV file saved successfully for Page: 59\n",
      "Processing Page:  60\n",
      "Page 60 has 10 links\n",
      "CSV file saved successfully for Page: 60\n",
      "Processing Page:  61\n",
      "Page 61 has 10 links\n",
      "CSV file saved successfully for Page: 61\n",
      "Processing Page:  62\n",
      "Page 62 has 10 links\n",
      "CSV file saved successfully for Page: 62\n",
      "Processing Page:  63\n",
      "Page 63 has 10 links\n",
      "CSV file saved successfully for Page: 63\n",
      "Processing Page:  64\n",
      "Page 64 has 10 links\n",
      "CSV file saved successfully for Page: 64\n",
      "Processing Page:  65\n",
      "Page 65 has 10 links\n",
      "CSV file saved successfully for Page: 65\n",
      "Processing Page:  66\n",
      "Page 66 has 10 links\n",
      "CSV file saved successfully for Page: 66\n",
      "Processing Page:  67\n",
      "Page 67 has 10 links\n",
      "CSV file saved successfully for Page: 67\n",
      "Processing Page:  68\n",
      "Page 68 has 10 links\n",
      "CSV file saved successfully for Page: 68\n",
      "Processing Page:  69\n",
      "Page 69 has 10 links\n",
      "CSV file saved successfully for Page: 69\n",
      "Processing Page:  70\n",
      "Page 70 has 10 links\n",
      "CSV file saved successfully for Page: 70\n",
      "Processing Page:  71\n",
      "Page 71 has 10 links\n",
      "CSV file saved successfully for Page: 71\n",
      "Processing Page:  72\n",
      "Page 72 has 10 links\n",
      "CSV file saved successfully for Page: 72\n",
      "Processing Page:  73\n",
      "Page 73 has 10 links\n",
      "CSV file saved successfully for Page: 73\n",
      "Processing Page:  74\n",
      "Page 74 has 10 links\n",
      "CSV file saved successfully for Page: 74\n",
      "Processing Page:  75\n",
      "Page 75 has 10 links\n",
      "CSV file saved successfully for Page: 75\n",
      "Processing Page:  76\n",
      "Page 76 has 10 links\n",
      "CSV file saved successfully for Page: 76\n",
      "Processing Page:  77\n",
      "Page 77 has 10 links\n",
      "CSV file saved successfully for Page: 77\n",
      "Processing Page:  78\n",
      "Page 78 has 10 links\n",
      "CSV file saved successfully for Page: 78\n",
      "Processing Page:  79\n",
      "Page 79 has 10 links\n",
      "CSV file saved successfully for Page: 79\n",
      "Processing Page:  80\n",
      "Page 80 has 10 links\n",
      "CSV file saved successfully for Page: 80\n",
      "Processing Page:  81\n",
      "Page 81 has 10 links\n",
      "CSV file saved successfully for Page: 81\n",
      "Processing Page:  82\n",
      "Page 82 has 10 links\n",
      "CSV file saved successfully for Page: 82\n",
      "Processing Page:  83\n",
      "Page 83 has 10 links\n",
      "CSV file saved successfully for Page: 83\n",
      "Processing Page:  84\n",
      "Page 84 has 10 links\n",
      "CSV file saved successfully for Page: 84\n",
      "Processing Page:  85\n",
      "Page 85 has 10 links\n",
      "CSV file saved successfully for Page: 85\n",
      "Processing Page:  86\n",
      "Page 86 has 10 links\n",
      "CSV file saved successfully for Page: 86\n"
     ]
    }
   ],
   "source": [
    "# Jan 2020 - Dec 2022 is in total 86 pages \n",
    "\n",
    "pages_to_get = 86\n",
    "\n",
    "# Writing to a file \n",
    "with open('sinarharian.csv', 'w', newline='') as f:\n",
    "  writer = csv.writer(f)\n",
    "  headers = [\"Title\", \"Date\", \"Time\", \"Link\", \"Article Description\"]\n",
    "  writer.writerow(headers)\n",
    "\n",
    "  # automatic goes to the next page from 1... n; python exclusive end \n",
    "\n",
    "  for page in range(1,pages_to_get+1):\n",
    "    print('Processing Page: ', page)\n",
    "    url = 'https://www.sinarharian.com.my/carian?query=vaksin&pgno='+str(page)\n",
    "\n",
    "    try:\n",
    "      # response is equivalent to enter a key in chrome \n",
    "      # prevent ip-block by adding fake devices accessing web pages \n",
    "      response = requests.get(url, headers={'User-Agent': UserAgent().random})\n",
    "\n",
    "      # this link give valid status code: 200 --> web scrap pass \n",
    "      # print(page.status_code)\n",
    "\n",
    "    except Exception as e:\n",
    "      error_type, error_obj, error_info = sys.exc_info()\n",
    "      print('Error Link: ', url)\n",
    "      print(error_type, 'Line: ', error_info.tb_lineno)\n",
    "\n",
    "      # ignore this paage and move on to next one\n",
    "      continue \n",
    "\n",
    "    # delay by 2 seconds to prevent ip block\n",
    "    time.sleep(2)\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    # inspect element attribute type and its names to take their information\n",
    "\n",
    "    attrs_code = 'col-md-8 col-content'\n",
    "    links = soup.find_all('div', attrs={'class':attrs_code})\n",
    "    # print(len(links))\n",
    "\n",
    "    # Check each page has 10 links\n",
    "    print(f'Page {page} has {len(links)} links')\n",
    "\n",
    "    extract_properties(links, writer)\n",
    "\n",
    "    print('CSV file saved successfully for Page: ' + str(page))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
